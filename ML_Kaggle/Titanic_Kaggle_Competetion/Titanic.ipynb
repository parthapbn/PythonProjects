{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting survival chance for passengers (in test set) using ML algorithms. \n",
    "# Exploration of Titanic survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\PBANE\\\\Titanic'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the environment and standard imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style= 'darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data upload\n",
    "trainSet = pd.read_csv('train.csv')\n",
    "testSet = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the training data and will work on this copy\n",
    "titanic = trainSet.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data exploration and overviewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a49a1bfb00>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(titanic.isnull(), yticklabels= False, cbar= False, cmap= 'viridis')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name variable contains first, middle, last and also title. We will keep the title part as this is probably give some picture on social status, age group etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newVarCreate(old):\n",
    "    new = old.str.split('.', n = 1).str[0].str.split(',').str[-1]\n",
    "    return(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Title'] = newVarCreate(titanic['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Countess</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PassengerId\n",
       "Title                     \n",
       " Capt                    1\n",
       " Col                     2\n",
       " Don                     1\n",
       " Dr                      7\n",
       " Jonkheer                1\n",
       " Lady                    1\n",
       " Major                   2\n",
       " Master                 40\n",
       " Miss                  182\n",
       " Mlle                    2\n",
       " Mme                     1\n",
       " Mr                    517\n",
       " Mrs                   125\n",
       " Ms                      1\n",
       " Rev                     6\n",
       " Sir                     1\n",
       " the Countess            1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby('Title')[['PassengerId']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level reduction of the Title variable by combining the rare titles\n",
    "def levelReducer(df):\n",
    "    df = df.replace(to_replace= [' Capt', ' Col', ' Major', ' Don', ' Dr', ' Jonkheer', ' Lady', ' Sir', ' the Countess'], value= 'ReputedPersonel')\n",
    "    df = df.replace(to_replace= [' Mlle', ' Ms', ' Miss'], value= 'Miss')\n",
    "    df = df.replace(to_replace = [' Mme', ' Mrs'], value = 'Mrs')\n",
    "    df = df.replace(to_replace= [' Rev'], value= 'Reverend')\n",
    "    df = df.replace(to_replace= [' Mr'], value= 'Mr')\n",
    "    return(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = levelReducer(titanic)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All NAs in Cabin column can be releveled as 'NoCabin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabinFix(df):\n",
    "    Cabin = df['Cabin'].str.split().str.get(0).str.split('').str.get(1)\n",
    "    Cabin = Cabin.fillna('NoCabin')\n",
    "    df['Cabin'] = Cabin\n",
    "    return(df['Cabin'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin'] = cabinFix(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a49a22c358>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= 'Cabin', data= titanic, hue= 'Survived')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is clear that survival rate was much higher among passengers travelling in cabin (possibly high income and status group) than regular travllers. We can club all classes of cabins into a single class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabinRegularizer(df):\n",
    "    df['Cabin'] = df['Cabin'].replace(to_replace= ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'], value= 'Cabin')\n",
    "    return(df['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin'] = cabinRegularizer(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a49a22ce10>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= 'Cabin', data= titanic, hue= 'Survived')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some people travelled with parents or sibs or both or alone. We will create a new variable named 'travelWthFamily'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travelPartner(df):\n",
    "    df['travelWthFamily'] = 'Parents_Sibs'\n",
    "    df.loc[(df['SibSp'] == 0) & (df['Parch'] == 0), 'travelWthFamily'] = 'Alone'\n",
    "    df.loc[(df['SibSp'] == 0) & (df['Parch'] != 0), 'travelWthFamily'] = 'Parents'\n",
    "    df.loc[(df['SibSp'] != 0) & (df['Parch'] == 0), 'travelWthFamily'] = 'Sibs'\n",
    "    return(df['travelWthFamily'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['travelWthFamily'] = travelPartner(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of family members travelling together\n",
    "def travelTogether(df):\n",
    "    travelTogether = df['SibSp'] + df['Parch'] + 1\n",
    "    return(travelTogether)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['travelTogether'] = travelTogether(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110152</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110413</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110465</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110564</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110813</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId\n",
       "Ticket             \n",
       "110152            3\n",
       "110413            3\n",
       "110465            2\n",
       "110564            1\n",
       "110813            1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby('Ticket')[['PassengerId']].count().head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we explore the ticket variable, we can see some people has same ticket number. Based on this finding we will create a new variable which will express whether the traveller was having co-ticket traveller or no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sameTktPassenger(df):\n",
    "    sameTktTravl = df.groupby('Ticket')[['PassengerId']].count().reset_index()\n",
    "    sameTktTravl = sameTktTravl.rename(columns = {'PassengerId':'sameTktTravl'})\n",
    "    df =pd.merge(df, sameTktTravl, on = 'Ticket', how = 'left')\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sameTktPassenger(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['farePerTkt'] = titanic['Fare']/titanic['sameTktTravl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a499f7ac18>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= 'Embarked', data= titanic, hue= 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Title</th>\n",
       "      <th>travelWthFamily</th>\n",
       "      <th>travelTogether</th>\n",
       "      <th>sameTktTravl</th>\n",
       "      <th>farePerTkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NoCabin</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Sibs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Sibs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NoCabin</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Alone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Sibs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NoCabin</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Alone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age     Fare    Cabin Title travelWthFamily  \\\n",
       "0         0       3    male  22.0   7.2500  NoCabin    Mr            Sibs   \n",
       "1         1       1  female  38.0  71.2833    Cabin   Mrs            Sibs   \n",
       "2         1       3  female  26.0   7.9250  NoCabin  Miss           Alone   \n",
       "3         1       1  female  35.0  53.1000    Cabin   Mrs            Sibs   \n",
       "4         0       3    male  35.0   8.0500  NoCabin    Mr           Alone   \n",
       "\n",
       "   travelTogether  sameTktTravl  farePerTkt  \n",
       "0               2             1      7.2500  \n",
       "1               2             1     71.2833  \n",
       "2               1             1      7.9250  \n",
       "3               2             2     26.5500  \n",
       "4               1             1      8.0500  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic =titanic.drop(['SibSp', 'Parch', 'Embarked'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a48b7da4e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure() \n",
    "sns.countplot(data= titanic, x= 'Pclass', hue= 'Survived')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Its evident that survival rate was much higher for first class travellers. It was little lower than 50% for 2nd class and mortality rate was very high among third class passengers. We can explore how this stastics change when we incorporate gender of the traveller as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a48b9bb978>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data= titanic, x= 'Sex', hue= 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x1a48b498b00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(data= titanic, x= 'Fare', y= 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a48bbdc358>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data= titanic, x= 'Title', hue= 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a48bc609e8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data= titanic, x= 'travelWthFamily', hue= 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor matrix and label creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = titanic.drop('Survived', axis= 1)\n",
    "yTrain = titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.model_selection as model_selection\n",
    "# XTrain, XTest, yTrain, yTest = model_selection.train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 10)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a49c325f28>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(XTrain.isnull(), yticklabels= False, cbar= False, cmap= 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Master</td>\n",
       "      <td>4.574167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miss</td>\n",
       "      <td>21.845638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr</td>\n",
       "      <td>32.368090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>35.788991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReputedPersonel</td>\n",
       "      <td>46.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reverend</td>\n",
       "      <td>43.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Title        Age\n",
       "0           Master   4.574167\n",
       "1             Miss  21.845638\n",
       "2               Mr  32.368090\n",
       "3              Mrs  35.788991\n",
       "4  ReputedPersonel  46.437500\n",
       "5         Reverend  43.166667"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.pivot_table('Age', aggfunc= 'mean', index= 'Title').reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Missing data imputation for age vatiable based on titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining imputeAge()\n",
    "\n",
    "def imputeAge(col):\n",
    "    Age = col[0]\n",
    "    Title = col[1]\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "        if Title == ' Master':\n",
    "            return 4\n",
    "        elif Title == 'Miss':\n",
    "            return 22\n",
    "        elif Title == 'Mr':\n",
    "            return 32\n",
    "        elif Title == 'Mrs':\n",
    "            return 36\n",
    "        elif Title == 'ReputedPersonel':\n",
    "            return 50\n",
    "        elif Title == 'Reverend':\n",
    "            return 46\n",
    "    else:\n",
    "        return Age              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['Age']= XTrain[['Age', 'Title']].apply(imputeAge, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4953ad048>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(XTrain.isnull(), yticklabels= False, cbar= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['Embarked'] = XTrain['Embarked'].fillna(value= 'Unknown')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will create a categorical variable from the Age variable to explore what is the impact of different age clusters on survival. Some exploration can be done to get the best cut combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ageGroup(df):\n",
    "    ageGroup = pd.cut(df['Age'], [0, 5, 20, 50, 80], labels= ['Baby', 'Child_Tins', 'Adult', 'Old'], include_lowest= True)\n",
    "    return(ageGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['ageGroup'] = ageGroup(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Title</th>\n",
       "      <th>travelWthFamily</th>\n",
       "      <th>travelTogether</th>\n",
       "      <th>sameTktTravl</th>\n",
       "      <th>farePerTkt</th>\n",
       "      <th>ageGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NoCabin</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Sibs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Sibs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NoCabin</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Alone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Sibs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NoCabin</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Alone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age     Fare    Cabin Title travelWthFamily  \\\n",
       "0       3    male  22.0   7.2500  NoCabin    Mr            Sibs   \n",
       "1       1  female  38.0  71.2833    Cabin   Mrs            Sibs   \n",
       "2       3  female  26.0   7.9250  NoCabin  Miss           Alone   \n",
       "3       1  female  35.0  53.1000    Cabin   Mrs            Sibs   \n",
       "4       3    male  35.0   8.0500  NoCabin    Mr           Alone   \n",
       "\n",
       "   travelTogether  sameTktTravl  farePerTkt ageGroup  \n",
       "0               2             1      7.2500    Adult  \n",
       "1               2             1     71.2833    Adult  \n",
       "2               1             1      7.9250    Adult  \n",
       "3               2             2     26.5500    Adult  \n",
       "4               1             1      8.0500    Adult  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicter and Dependent variable matrix seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['Pclass']= XTrain['Pclass'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Pclass             891 non-null category\n",
      "Sex                891 non-null object\n",
      "Age                891 non-null float64\n",
      "Fare               891 non-null float64\n",
      "Cabin              891 non-null object\n",
      "Title              891 non-null object\n",
      "travelWthFamily    891 non-null object\n",
      "travelTogether     891 non-null int64\n",
      "sameTktTravl       891 non-null int64\n",
      "farePerTkt         891 non-null float64\n",
      "ageGroup           891 non-null category\n",
      "dtypes: category(2), float64(3), int64(2), object(4)\n",
      "memory usage: 111.6+ KB\n"
     ]
    }
   ],
   "source": [
    "XTrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>travelTogether</th>\n",
       "      <th>sameTktTravl</th>\n",
       "      <th>farePerTkt</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_NoCabin</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_ReputedPersonel</th>\n",
       "      <th>Title_Reverend</th>\n",
       "      <th>travelWthFamily_Parents</th>\n",
       "      <th>travelWthFamily_Parents_Sibs</th>\n",
       "      <th>travelWthFamily_Sibs</th>\n",
       "      <th>ageGroup_Child_Tins</th>\n",
       "      <th>ageGroup_Adult</th>\n",
       "      <th>ageGroup_Old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  travelTogether  sameTktTravl  farePerTkt  Pclass_2  \\\n",
       "0  22.0   7.2500               2             1      7.2500         0   \n",
       "1  38.0  71.2833               2             1     71.2833         0   \n",
       "\n",
       "   Pclass_3  Sex_male  Cabin_NoCabin  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0         1         1              1           0         1          0   \n",
       "1         0         0              0           0         0          1   \n",
       "\n",
       "   Title_ReputedPersonel  Title_Reverend  travelWthFamily_Parents  \\\n",
       "0                      0               0                        0   \n",
       "1                      0               0                        0   \n",
       "\n",
       "   travelWthFamily_Parents_Sibs  travelWthFamily_Sibs  ageGroup_Child_Tins  \\\n",
       "0                             0                     1                    0   \n",
       "1                             0                     1                    0   \n",
       "\n",
       "   ageGroup_Adult  ageGroup_Old  \n",
       "0               1             0  \n",
       "1               1             0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain = pd.get_dummies(XTrain, drop_first= True)\n",
    "XTrain.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Either both or neither of `x` and `y` must be specified (but try passing to `data`, which is more flexible).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-45168375bf76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mscatterplot\u001b[1;34m(x, y, hue, style, size, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[0mx_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_bins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m         \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_jitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_jitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m     )\n\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m         plot_data = self.establish_variables(\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[1;34m(self, x, y, hue, size, style, units, data)\u001b[0m\n\u001b[0;32m    164\u001b[0m             err = (\"Either both or neither of `x` and `y` must be specified \"\n\u001b[0;32m    165\u001b[0m                    \"(but try passing to `data`, which is more flexible).\")\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m# ---- Post-processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Either both or neither of `x` and `y` must be specified (but try passing to `data`, which is more flexible)."
     ]
    }
   ],
   "source": [
    "sns.scatterplot(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logClf = LogisticRegression(random_state= 42)\n",
    "logClf = logClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "score = model_selection.cross_val_score(logClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83333333 0.8        0.7752809  0.85393258 0.79775281 0.78651685\n",
      " 0.83146067 0.80898876 0.86516854 0.86363636]\n",
      "0.8216070820565203\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sgdClf', SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sgdClf = Pipeline((\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgdClf', SGDClassifier(random_state = 42))\n",
    "))\n",
    "\n",
    "sgdClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.77777778 0.69662921 0.79775281 0.85393258 0.73033708\n",
      " 0.76404494 0.85393258 0.83146067 0.71590909]\n",
      "0.7688443422993985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "scoresSGD= model_selection.cross_val_score(sgdClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoresSGD)\n",
    "print(scoresSGD.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Linear\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClf = Pipeline((\n",
    "('scaller', StandardScaler()),\n",
    "('linearSVC', LinearSVC(C= 1, loss= 'hinge', random_state= 42)),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaller', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearSVC', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=42, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82222222 0.85555556 0.7752809  0.87640449 0.82022472 0.80898876\n",
      " 0.80898876 0.79775281 0.88764045 0.85227273]\n",
      "0.8305331403926909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "scoresSVM= model_selection.cross_val_score(svmClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoresSVM)\n",
    "print(scoresSVM.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaller', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svmClf', SVC(C=1, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=42,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svmPolyClf = Pipeline((\n",
    "    ('scaller', StandardScaler()),\n",
    "    ('svmClf', SVC(kernel= 'poly', degree = 2, coef0 = 1, C= 1, random_state= 42))\n",
    "))\n",
    "svmPolyClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82222222 0.85555556 0.75280899 0.87640449 0.83146067 0.80898876\n",
      " 0.83146067 0.80898876 0.87640449 0.84090909]\n",
      "0.8305203722619453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "scoresvmPoly = model_selection.cross_val_score(svmPolyClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoresvmPoly)\n",
    "print(scoresvmPoly.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaller', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svmClf', SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbfSVMClf = Pipeline((\n",
    "    ('scaller', StandardScaler()),\n",
    "    ('svmClf', SVC(kernel= 'rbf', gamma= .1, C= 10000, random_state= 42))\n",
    "    ))\n",
    "\n",
    "rbfSVMClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73333333 0.75555556 0.69662921 0.78651685 0.84269663 0.80898876\n",
      " 0.79775281 0.75280899 0.82022472 0.85227273]\n",
      "0.7846779593689706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "scoreSVCrbfClf = model_selection.cross_val_score(rbfSVMClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoreSVCrbfClf)\n",
    "print(scoreSVCrbfClf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decession Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "treeClf = DecisionTreeClassifier(max_depth= 10)\n",
    "treeClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382716049382716"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeClf.score(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78888889 0.83333333 0.74157303 0.7752809  0.86516854 0.83146067\n",
      " 0.80898876 0.82022472 0.79775281 0.82954545]\n",
      "0.8092217114969923\n"
     ]
    }
   ],
   "source": [
    "## Cross validation\n",
    "scoreTreeClf = model_selection.cross_val_score(treeClf, XTrain, yTrain, cv = 10, scoring= 'accuracy')\n",
    "print(scoreTreeClf)\n",
    "print(scoreTreeClf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagClf = BaggingClassifier(base_estimator= DecisionTreeClassifier(), n_estimators= 500, bootstrap= True, n_jobs= -1, oob_score= True, random_state= 42)\n",
    "bagClf = bagClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260381593714927"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagClf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76666667 0.84444444 0.74157303 0.83146067 0.84269663 0.84269663\n",
      " 0.83146067 0.80898876 0.86516854 0.85227273]\n",
      "0.8227428782204063\n"
     ]
    }
   ],
   "source": [
    "scoresBagClf = model_selection.cross_val_score(bagClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoresBagClf)\n",
    "print(scoresBagClf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forestClf = RandomForestClassifier(n_estimators= 500, n_jobs= -1, bootstrap= True, oob_score= True, random_state= 42)\n",
    "forestClf = forestClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8271604938271605"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestClf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77777778 0.85555556 0.73033708 0.85393258 0.84269663 0.84269663\n",
      " 0.83146067 0.7752809  0.85393258 0.86363636]\n",
      "0.8227306775621382\n"
     ]
    }
   ],
   "source": [
    "scoresForest = model_selection.cross_val_score(forestClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoresForest)\n",
    "print(scoresForest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for n_estimatores = 10\n",
      "oob score is = 0.7890011223344556\n",
      "==============================================================================\n",
      "for n_estimatores = 20\n",
      "oob score is = 0.8058361391694725\n",
      "==============================================================================\n",
      "for n_estimatores = 30\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 40\n",
      "oob score is = 0.8125701459034792\n",
      "==============================================================================\n",
      "for n_estimatores = 50\n",
      "oob score is = 0.8148148148148148\n",
      "==============================================================================\n",
      "for n_estimatores = 60\n",
      "oob score is = 0.8170594837261503\n",
      "==============================================================================\n",
      "for n_estimatores = 70\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 80\n",
      "oob score is = 0.8170594837261503\n",
      "==============================================================================\n",
      "for n_estimatores = 90\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 100\n",
      "oob score is = 0.8204264870931538\n",
      "==============================================================================\n",
      "for n_estimatores = 110\n",
      "oob score is = 0.819304152637486\n",
      "==============================================================================\n",
      "for n_estimatores = 120\n",
      "oob score is = 0.8125701459034792\n",
      "==============================================================================\n",
      "for n_estimatores = 130\n",
      "oob score is = 0.8125701459034792\n",
      "==============================================================================\n",
      "for n_estimatores = 140\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 150\n",
      "oob score is = 0.8148148148148148\n",
      "==============================================================================\n",
      "for n_estimatores = 160\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 170\n",
      "oob score is = 0.819304152637486\n",
      "==============================================================================\n",
      "for n_estimatores = 180\n",
      "oob score is = 0.8170594837261503\n",
      "==============================================================================\n",
      "for n_estimatores = 190\n",
      "oob score is = 0.8170594837261503\n",
      "==============================================================================\n",
      "for n_estimatores = 200\n",
      "oob score is = 0.8159371492704826\n",
      "==============================================================================\n",
      "for n_estimatores = 210\n",
      "oob score is = 0.8159371492704826\n",
      "==============================================================================\n",
      "for n_estimatores = 220\n",
      "oob score is = 0.8159371492704826\n",
      "==============================================================================\n",
      "for n_estimatores = 230\n",
      "oob score is = 0.8159371492704826\n",
      "==============================================================================\n",
      "for n_estimatores = 240\n",
      "oob score is = 0.8170594837261503\n",
      "==============================================================================\n",
      "for n_estimatores = 250\n",
      "oob score is = 0.8170594837261503\n",
      "==============================================================================\n",
      "for n_estimatores = 260\n",
      "oob score is = 0.8159371492704826\n",
      "==============================================================================\n",
      "for n_estimatores = 270\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 280\n",
      "oob score is = 0.8204264870931538\n",
      "==============================================================================\n",
      "for n_estimatores = 290\n",
      "oob score is = 0.8215488215488216\n",
      "==============================================================================\n",
      "for n_estimatores = 300\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 310\n",
      "oob score is = 0.8181818181818182\n",
      "==============================================================================\n",
      "for n_estimatores = 320\n",
      "oob score is = 0.819304152637486\n",
      "==============================================================================\n",
      "for n_estimatores = 330\n",
      "oob score is = 0.8204264870931538\n",
      "==============================================================================\n",
      "for n_estimatores = 340\n",
      "oob score is = 0.8204264870931538\n",
      "==============================================================================\n",
      "for n_estimatores = 350\n",
      "oob score is = 0.8215488215488216\n",
      "==============================================================================\n",
      "for n_estimatores = 360\n",
      "oob score is = 0.8237934904601572\n",
      "==============================================================================\n",
      "for n_estimatores = 370\n",
      "oob score is = 0.8260381593714927\n",
      "==============================================================================\n",
      "for n_estimatores = 380\n",
      "oob score is = 0.8237934904601572\n",
      "==============================================================================\n",
      "for n_estimatores = 390\n",
      "oob score is = 0.8215488215488216\n",
      "==============================================================================\n",
      "for n_estimatores = 400\n",
      "oob score is = 0.8226711560044894\n",
      "==============================================================================\n",
      "for n_estimatores = 410\n",
      "oob score is = 0.8215488215488216\n",
      "==============================================================================\n",
      "for n_estimatores = 420\n",
      "oob score is = 0.8204264870931538\n",
      "==============================================================================\n",
      "for n_estimatores = 430\n",
      "oob score is = 0.8249158249158249\n",
      "==============================================================================\n",
      "for n_estimatores = 440\n",
      "oob score is = 0.8249158249158249\n",
      "==============================================================================\n",
      "for n_estimatores = 450\n",
      "oob score is = 0.8226711560044894\n",
      "==============================================================================\n",
      "for n_estimatores = 460\n",
      "oob score is = 0.8226711560044894\n",
      "==============================================================================\n",
      "for n_estimatores = 470\n",
      "oob score is = 0.8215488215488216\n",
      "==============================================================================\n",
      "for n_estimatores = 480\n",
      "oob score is = 0.8249158249158249\n",
      "==============================================================================\n",
      "for n_estimatores = 490\n",
      "oob score is = 0.8237934904601572\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 500, 10):\n",
    "    forestClf = RandomForestClassifier(n_estimators= i, n_jobs= -1, oob_score= True, random_state= 42)\n",
    "    forestClf.fit(XTrain, yTrain)\n",
    "    oob = forestClf.oob_score_\n",
    "    print(\"for n_estimatores = \"+str(i))\n",
    "    print(\"oob score is = \"+str(oob))\n",
    "    print(\"==============================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extratree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "           oob_score=True, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "eTreeClf= ExtraTreesClassifier(n_estimators= 500, n_jobs= -1, bootstrap= True, oob_score= True, random_state= 42)\n",
    "eTreeClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819304152637486"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eTreeClf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8        0.85555556 0.74157303 0.80898876 0.83146067 0.85393258\n",
      " 0.82022472 0.7752809  0.87640449 0.85227273]\n",
      "0.8215693451367608\n"
     ]
    }
   ],
   "source": [
    "scoreET= model_selection.cross_val_score(eTreeClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoreET)\n",
    "print(scoreET.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "logClf = logClf\n",
    "linearSVM = svmClf\n",
    "polySVM = svmPolyClf\n",
    "treeClf = treeClf\n",
    "bagClf = bagClf\n",
    "forestClf = forestClf\n",
    "eTreeClf = eTreeClf\n",
    "aBoostClf = aBoostClf\n",
    "gBoostClf = gBoostClf\n",
    "\n",
    "\n",
    "votinfClf = VotingClassifier(\n",
    "    estimators= [('logClf', logClf),\n",
    "                 ('linearSVM', linearSVM),\n",
    "                 ('bagClf', bagClf),\n",
    "                 ('forestClf', forestClf),\n",
    "                 ('eTreeClf', eTreeClf),\n",
    "                 ('polySVM', polySVM),\n",
    "                 ('gBoostClf', gBoostClf),\n",
    "                ('aBoostClf', aBoostClf)], voting= 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logClf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)), ('linearSVM',...hm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.1, n_estimators=500, random_state=42))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votinfClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\PBANE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "scoreV= model_selection.cross_val_score(votinfClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327925320621951"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreV.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "aBoostClf= AdaBoostClassifier(learning_rate= .1, n_estimators= 500, random_state= 42)\n",
    "aBoostClf= aBoostClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76666667 0.8        0.79775281 0.86516854 0.84269663 0.78651685\n",
      " 0.85393258 0.84269663 0.85393258 0.84090909]\n",
      "0.8250272386789241\n"
     ]
    }
   ],
   "source": [
    "scoresAB= model_selection.cross_val_score(aBoostClf, XTrain, yTrain, cv= 10)\n",
    "print(scoresAB)\n",
    "print(scoresAB.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiant Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "              n_iter_no_change=None, presort='auto', random_state=42,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gBoostClf= GradientBoostingClassifier(learning_rate= .1, n_estimators= 500, random_state= 42)\n",
    "gBoostClf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81111111 0.84444444 0.75280899 0.83146067 0.84269663 0.83146067\n",
      " 0.86516854 0.84269663 0.84269663 0.80681818]\n",
      "0.8271362501418681\n"
     ]
    }
   ],
   "source": [
    "scoreGB= model_selection.cross_val_score(gBoostClf, XTrain, yTrain, cv= 10, scoring= 'accuracy')\n",
    "print(scoreGB)\n",
    "print(scoreGB.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = titanicOriginal.copy()\n",
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Read data from Titanic dataset.\n",
    "titanic_url = ('https://raw.githubusercontent.com/amueller/'\n",
    "               'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')\n",
    "data = pd.read_csv(titanic_url)\n",
    "\n",
    "# We will train our classifier with the following features:\n",
    "# Numeric Features:\n",
    "# - age: float.\n",
    "# - fare: float.\n",
    "# Categorical Features:\n",
    "# - embarked: categories encoded as strings {'C', 'S', 'Q'}.\n",
    "# - sex: categories encoded as strings {'female', 'male'}.\n",
    "# - pclass: ordinal integers {1, 2, 3}.\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocessor.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.039005</td>\n",
       "      <td>3.442584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.215952</td>\n",
       "      <td>2.286639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.131977</td>\n",
       "      <td>2.286639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038512</td>\n",
       "      <td>2.286639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.349075</td>\n",
       "      <td>2.286639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.433827</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.596589</td>\n",
       "      <td>0.863800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.736169</td>\n",
       "      <td>-0.643464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.821414</td>\n",
       "      <td>0.351847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.216729</td>\n",
       "      <td>0.313661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.356309</td>\n",
       "      <td>3.755557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.891698</td>\n",
       "      <td>3.755557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.426593</td>\n",
       "      <td>0.696398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.271558</td>\n",
       "      <td>0.881040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.914386</td>\n",
       "      <td>-0.063437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.142224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.426593</td>\n",
       "      <td>4.142160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.588862</td>\n",
       "      <td>4.142160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.193547</td>\n",
       "      <td>0.831577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.503617</td>\n",
       "      <td>0.811276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.581134</td>\n",
       "      <td>0.372631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.356309</td>\n",
       "      <td>0.372631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271558</td>\n",
       "      <td>-0.063437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.968722</td>\n",
       "      <td>3.755557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.039005</td>\n",
       "      <td>3.644466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.349075</td>\n",
       "      <td>-0.140774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.349075</td>\n",
       "      <td>1.117482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.814180</td>\n",
       "      <td>1.117482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.426099</td>\n",
       "      <td>1.978902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>-1.201768</td>\n",
       "      <td>-0.491609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>-0.581628</td>\n",
       "      <td>-0.490805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>-0.581628</td>\n",
       "      <td>-0.469456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.487824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.497491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.487824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>0.232306</td>\n",
       "      <td>-0.459789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.658652</td>\n",
       "      <td>-0.503693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1.666379</td>\n",
       "      <td>-0.493624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>-0.891698</td>\n",
       "      <td>-0.517873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>-0.659145</td>\n",
       "      <td>-0.517873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1.356309</td>\n",
       "      <td>-0.508125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.475015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.497491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.487824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>-0.077764</td>\n",
       "      <td>-0.332183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>-0.659145</td>\n",
       "      <td>-0.503291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>-0.194040</td>\n",
       "      <td>-0.475981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.503291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.503617</td>\n",
       "      <td>-0.459789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>-0.194040</td>\n",
       "      <td>-0.364003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>-1.124250</td>\n",
       "      <td>-0.364003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1.240033</td>\n",
       "      <td>-0.503774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.503774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.363924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-1.163009</td>\n",
       "      <td>-0.364003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.364003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>-0.232799</td>\n",
       "      <td>-0.503774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>-0.194040</td>\n",
       "      <td>-0.503774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>-0.039005</td>\n",
       "      <td>-0.491207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    2    3    4    5    6    7    8    9    10\n",
       "0    -0.039005  3.442584  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "1    -2.215952  2.286639  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "2    -2.131977  2.286639  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "3     0.038512  2.286639  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "4    -0.349075  2.286639  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "5     1.433827 -0.130140  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "6     2.596589  0.863800  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "7     0.736169 -0.643464  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "8     1.821414  0.351847  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "9     3.216729  0.313661  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "10    1.356309  3.755557  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "11   -0.891698  3.755557  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "12   -0.426593  0.696398  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "13   -0.271558  0.881040  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "14    3.914386 -0.063437  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "15   -0.116523 -0.142224  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "16   -0.426593  4.142160  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "17    1.588862  4.142160  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "18    0.193547  0.831577  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "19    0.503617  0.811276  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "20    0.581134  0.372631  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "21    1.356309  0.372631  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "22   -0.271558 -0.063437  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "23    0.968722  3.755557  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "24   -0.039005  3.644466  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "25   -0.349075 -0.140774  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "26   -0.349075  1.117482  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "27   -0.814180  1.117482  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "28    0.426099  1.978902  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "29   -0.116523 -0.130140  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "...        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "1279 -1.201768 -0.491609  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "1280 -0.581628 -0.490805  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1281 -0.581628 -0.469456  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1282 -0.116523 -0.487824  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1283 -0.116523 -0.497491  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1284 -0.116523 -0.487824  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1285  0.232306 -0.459789  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1286  0.658652 -0.503693  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "1287  1.666379 -0.493624  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1288 -0.891698 -0.517873  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1289 -0.659145 -0.517873  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1290  1.356309 -0.508125  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "1291 -0.116523 -0.475015  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1292 -0.116523 -0.497491  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1293 -0.116523 -0.487824  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1294 -0.077764 -0.332183  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1295 -0.659145 -0.503291  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1296 -0.194040 -0.475981  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1297 -0.116523 -0.503291  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1298  0.503617 -0.459789  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1299 -0.194040 -0.364003  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1300 -1.124250 -0.364003  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "1301  1.240033 -0.503774  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1302 -0.116523 -0.503774  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1303 -0.116523 -0.363924  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1304 -1.163009 -0.364003  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "1305 -0.116523 -0.364003  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "1306 -0.232799 -0.503774  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1307 -0.194040 -0.503774  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "1308 -0.039005 -0.491207  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "\n",
       "[1309 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainDummy = pd.get_dummies(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>travelTogether</th>\n",
       "      <th>sameTktTravl</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_Cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>travelWthFamily_Alone</th>\n",
       "      <th>travelWthFamily_Parents</th>\n",
       "      <th>travelWthFamily_Parents_Sibs</th>\n",
       "      <th>travelWthFamily_Sibs</th>\n",
       "      <th>genderClass_female_1</th>\n",
       "      <th>genderClass_female_2</th>\n",
       "      <th>genderClass_female_3</th>\n",
       "      <th>genderClass_male_1</th>\n",
       "      <th>genderClass_male_2</th>\n",
       "      <th>genderClass_male_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>45.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>3</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2</td>\n",
       "      <td>29.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>3</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>3</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>2</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>3</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>3</td>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>3</td>\n",
       "      <td>63.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>3</td>\n",
       "      <td>35.85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>3</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>3</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>3</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>3</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>3</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>3</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>34.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>3</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3</td>\n",
       "      <td>21.85</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3</td>\n",
       "      <td>32.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>16.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>32.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>41.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass    Age  SibSp  Parch      Fare  travelTogether  sameTktTravl  \\\n",
       "331       1  45.50      0      0   28.5000               1             1   \n",
       "733       2  23.00      0      0   13.0000               1             1   \n",
       "382       3  32.00      0      0    7.9250               1             1   \n",
       "704       3  26.00      1      0    7.8542               2             1   \n",
       "813       3   6.00      4      2   31.2750               7             7   \n",
       "118       1  24.00      0      1  247.5208               2             2   \n",
       "536       1  45.00      0      0   26.5500               1             1   \n",
       "361       2  29.00      1      0   27.7208               2             1   \n",
       "29        3  32.21      0      0    7.8958               1             1   \n",
       "55        1  32.21      0      0   35.5000               1             1   \n",
       "865       2  42.00      0      0   13.0000               1             1   \n",
       "595       3  36.00      1      1   24.1500               3             3   \n",
       "239       2  33.00      0      0   12.2750               1             1   \n",
       "721       3  17.00      1      0    7.0542               2             1   \n",
       "81        3  29.00      0      0    9.5000               1             1   \n",
       "259       2  50.00      0      1   26.0000               2             2   \n",
       "486       1  35.00      1      0   90.0000               2             2   \n",
       "716       1  38.00      0      0  227.5250               1             4   \n",
       "800       2  34.00      0      0   13.0000               1             2   \n",
       "781       1  17.00      1      0   57.0000               2             2   \n",
       "542       3  11.00      4      2   31.2750               7             7   \n",
       "326       3  61.00      0      0    6.2375               1             1   \n",
       "534       3  30.00      0      0    8.6625               1             1   \n",
       "535       2   7.00      0      2   26.2500               3             3   \n",
       "483       3  63.00      0      0    9.5875               1             1   \n",
       "762       3  20.00      0      0    7.2292               1             1   \n",
       "533       3  35.85      0      2   22.3583               3             2   \n",
       "713       3  29.00      0      0    9.4833               1             1   \n",
       "390       1  36.00      1      2  120.0000               4             4   \n",
       "495       3  32.21      0      0   14.4583               1             2   \n",
       "..      ...    ...    ...    ...       ...             ...           ...   \n",
       "276       3  45.00      0      0    7.7500               1             1   \n",
       "191       2  19.00      0      0   13.0000               1             1   \n",
       "385       2  18.00      0      0   73.5000               1             5   \n",
       "805       3  31.00      0      0    7.7750               1             1   \n",
       "413       2  32.21      0      0    0.0000               1             3   \n",
       "491       3  21.00      0      0    7.2500               1             1   \n",
       "343       2  25.00      0      0   13.0000               1             1   \n",
       "769       3  32.00      0      0    8.3625               1             1   \n",
       "308       2  30.00      1      0   24.0000               2             2   \n",
       "661       3  40.00      0      0    7.2250               1             1   \n",
       "130       3  33.00      0      0    7.8958               1             1   \n",
       "663       3  36.00      0      0    7.4958               1             1   \n",
       "871       1  47.00      1      1   52.5542               3             2   \n",
       "99        2  34.00      1      0   26.0000               2             2   \n",
       "372       3  19.00      0      0    8.0500               1             1   \n",
       "87        3  32.21      0      0    8.0500               1             1   \n",
       "458       2  50.00      0      0   10.5000               1             1   \n",
       "330       3  21.85      2      0   23.2500               3             2   \n",
       "214       3  32.21      1      0    7.7500               2             1   \n",
       "466       2  32.21      0      0    0.0000               1             3   \n",
       "121       3  32.21      0      0    8.0500               1             1   \n",
       "614       3  35.00      0      0    8.0500               1             1   \n",
       "20        2  35.00      0      0   26.0000               1             2   \n",
       "700       1  18.00      1      0  227.5250               2             4   \n",
       "71        3  16.00      5      2   46.9000               8             6   \n",
       "106       3  21.00      0      0    7.6500               1             1   \n",
       "270       1  32.21      0      0   31.0000               1             2   \n",
       "860       3  41.00      2      0   14.1083               3             1   \n",
       "435       1  14.00      1      2  120.0000               4             4   \n",
       "102       1  21.00      0      1   77.2875               2             2   \n",
       "\n",
       "     Sex_female  Sex_male  Cabin_Cabin         ...          \\\n",
       "331           0         1            1         ...           \n",
       "733           0         1            0         ...           \n",
       "382           0         1            0         ...           \n",
       "704           0         1            0         ...           \n",
       "813           1         0            0         ...           \n",
       "118           0         1            1         ...           \n",
       "536           0         1            1         ...           \n",
       "361           0         1            0         ...           \n",
       "29            0         1            0         ...           \n",
       "55            0         1            1         ...           \n",
       "865           1         0            0         ...           \n",
       "595           0         1            0         ...           \n",
       "239           0         1            0         ...           \n",
       "721           0         1            0         ...           \n",
       "81            0         1            0         ...           \n",
       "259           1         0            0         ...           \n",
       "486           1         0            1         ...           \n",
       "716           1         0            1         ...           \n",
       "800           0         1            0         ...           \n",
       "781           1         0            1         ...           \n",
       "542           1         0            0         ...           \n",
       "326           0         1            0         ...           \n",
       "534           1         0            0         ...           \n",
       "535           1         0            0         ...           \n",
       "483           1         0            0         ...           \n",
       "762           0         1            0         ...           \n",
       "533           1         0            0         ...           \n",
       "713           0         1            0         ...           \n",
       "390           0         1            1         ...           \n",
       "495           0         1            0         ...           \n",
       "..          ...       ...          ...         ...           \n",
       "276           1         0            0         ...           \n",
       "191           0         1            0         ...           \n",
       "385           0         1            0         ...           \n",
       "805           0         1            0         ...           \n",
       "413           0         1            0         ...           \n",
       "491           0         1            0         ...           \n",
       "343           0         1            0         ...           \n",
       "769           0         1            0         ...           \n",
       "308           0         1            0         ...           \n",
       "661           0         1            0         ...           \n",
       "130           0         1            0         ...           \n",
       "663           0         1            0         ...           \n",
       "871           1         0            1         ...           \n",
       "99            0         1            0         ...           \n",
       "372           0         1            0         ...           \n",
       "87            0         1            0         ...           \n",
       "458           1         0            0         ...           \n",
       "330           1         0            0         ...           \n",
       "214           0         1            0         ...           \n",
       "466           0         1            0         ...           \n",
       "121           0         1            0         ...           \n",
       "614           0         1            0         ...           \n",
       "20            0         1            0         ...           \n",
       "700           1         0            1         ...           \n",
       "71            1         0            0         ...           \n",
       "106           1         0            0         ...           \n",
       "270           0         1            0         ...           \n",
       "860           0         1            0         ...           \n",
       "435           1         0            1         ...           \n",
       "102           0         1            1         ...           \n",
       "\n",
       "     travelWthFamily_Alone  travelWthFamily_Parents  \\\n",
       "331                      1                        0   \n",
       "733                      1                        0   \n",
       "382                      1                        0   \n",
       "704                      0                        0   \n",
       "813                      0                        0   \n",
       "118                      0                        1   \n",
       "536                      1                        0   \n",
       "361                      0                        0   \n",
       "29                       1                        0   \n",
       "55                       1                        0   \n",
       "865                      1                        0   \n",
       "595                      0                        0   \n",
       "239                      1                        0   \n",
       "721                      0                        0   \n",
       "81                       1                        0   \n",
       "259                      0                        1   \n",
       "486                      0                        0   \n",
       "716                      1                        0   \n",
       "800                      1                        0   \n",
       "781                      0                        0   \n",
       "542                      0                        0   \n",
       "326                      1                        0   \n",
       "534                      1                        0   \n",
       "535                      0                        1   \n",
       "483                      1                        0   \n",
       "762                      1                        0   \n",
       "533                      0                        1   \n",
       "713                      1                        0   \n",
       "390                      0                        0   \n",
       "495                      1                        0   \n",
       "..                     ...                      ...   \n",
       "276                      1                        0   \n",
       "191                      1                        0   \n",
       "385                      1                        0   \n",
       "805                      1                        0   \n",
       "413                      1                        0   \n",
       "491                      1                        0   \n",
       "343                      1                        0   \n",
       "769                      1                        0   \n",
       "308                      0                        0   \n",
       "661                      1                        0   \n",
       "130                      1                        0   \n",
       "663                      1                        0   \n",
       "871                      0                        0   \n",
       "99                       0                        0   \n",
       "372                      1                        0   \n",
       "87                       1                        0   \n",
       "458                      1                        0   \n",
       "330                      0                        0   \n",
       "214                      0                        0   \n",
       "466                      1                        0   \n",
       "121                      1                        0   \n",
       "614                      1                        0   \n",
       "20                       1                        0   \n",
       "700                      0                        0   \n",
       "71                       0                        0   \n",
       "106                      1                        0   \n",
       "270                      1                        0   \n",
       "860                      0                        0   \n",
       "435                      0                        0   \n",
       "102                      0                        1   \n",
       "\n",
       "     travelWthFamily_Parents_Sibs  travelWthFamily_Sibs  genderClass_female_1  \\\n",
       "331                             0                     0                     0   \n",
       "733                             0                     0                     0   \n",
       "382                             0                     0                     0   \n",
       "704                             0                     1                     0   \n",
       "813                             1                     0                     0   \n",
       "118                             0                     0                     0   \n",
       "536                             0                     0                     0   \n",
       "361                             0                     1                     0   \n",
       "29                              0                     0                     0   \n",
       "55                              0                     0                     0   \n",
       "865                             0                     0                     0   \n",
       "595                             1                     0                     0   \n",
       "239                             0                     0                     0   \n",
       "721                             0                     1                     0   \n",
       "81                              0                     0                     0   \n",
       "259                             0                     0                     0   \n",
       "486                             0                     1                     1   \n",
       "716                             0                     0                     1   \n",
       "800                             0                     0                     0   \n",
       "781                             0                     1                     1   \n",
       "542                             1                     0                     0   \n",
       "326                             0                     0                     0   \n",
       "534                             0                     0                     0   \n",
       "535                             0                     0                     0   \n",
       "483                             0                     0                     0   \n",
       "762                             0                     0                     0   \n",
       "533                             0                     0                     0   \n",
       "713                             0                     0                     0   \n",
       "390                             1                     0                     0   \n",
       "495                             0                     0                     0   \n",
       "..                            ...                   ...                   ...   \n",
       "276                             0                     0                     0   \n",
       "191                             0                     0                     0   \n",
       "385                             0                     0                     0   \n",
       "805                             0                     0                     0   \n",
       "413                             0                     0                     0   \n",
       "491                             0                     0                     0   \n",
       "343                             0                     0                     0   \n",
       "769                             0                     0                     0   \n",
       "308                             0                     1                     0   \n",
       "661                             0                     0                     0   \n",
       "130                             0                     0                     0   \n",
       "663                             0                     0                     0   \n",
       "871                             1                     0                     1   \n",
       "99                              0                     1                     0   \n",
       "372                             0                     0                     0   \n",
       "87                              0                     0                     0   \n",
       "458                             0                     0                     0   \n",
       "330                             0                     1                     0   \n",
       "214                             0                     1                     0   \n",
       "466                             0                     0                     0   \n",
       "121                             0                     0                     0   \n",
       "614                             0                     0                     0   \n",
       "20                              0                     0                     0   \n",
       "700                             0                     1                     1   \n",
       "71                              1                     0                     0   \n",
       "106                             0                     0                     0   \n",
       "270                             0                     0                     0   \n",
       "860                             0                     1                     0   \n",
       "435                             1                     0                     1   \n",
       "102                             0                     0                     0   \n",
       "\n",
       "     genderClass_female_2  genderClass_female_3  genderClass_male_1  \\\n",
       "331                     0                     0                   1   \n",
       "733                     0                     0                   0   \n",
       "382                     0                     0                   0   \n",
       "704                     0                     0                   0   \n",
       "813                     0                     1                   0   \n",
       "118                     0                     0                   1   \n",
       "536                     0                     0                   1   \n",
       "361                     0                     0                   0   \n",
       "29                      0                     0                   0   \n",
       "55                      0                     0                   1   \n",
       "865                     1                     0                   0   \n",
       "595                     0                     0                   0   \n",
       "239                     0                     0                   0   \n",
       "721                     0                     0                   0   \n",
       "81                      0                     0                   0   \n",
       "259                     1                     0                   0   \n",
       "486                     0                     0                   0   \n",
       "716                     0                     0                   0   \n",
       "800                     0                     0                   0   \n",
       "781                     0                     0                   0   \n",
       "542                     0                     1                   0   \n",
       "326                     0                     0                   0   \n",
       "534                     0                     1                   0   \n",
       "535                     1                     0                   0   \n",
       "483                     0                     1                   0   \n",
       "762                     0                     0                   0   \n",
       "533                     0                     1                   0   \n",
       "713                     0                     0                   0   \n",
       "390                     0                     0                   1   \n",
       "495                     0                     0                   0   \n",
       "..                    ...                   ...                 ...   \n",
       "276                     0                     1                   0   \n",
       "191                     0                     0                   0   \n",
       "385                     0                     0                   0   \n",
       "805                     0                     0                   0   \n",
       "413                     0                     0                   0   \n",
       "491                     0                     0                   0   \n",
       "343                     0                     0                   0   \n",
       "769                     0                     0                   0   \n",
       "308                     0                     0                   0   \n",
       "661                     0                     0                   0   \n",
       "130                     0                     0                   0   \n",
       "663                     0                     0                   0   \n",
       "871                     0                     0                   0   \n",
       "99                      0                     0                   0   \n",
       "372                     0                     0                   0   \n",
       "87                      0                     0                   0   \n",
       "458                     1                     0                   0   \n",
       "330                     0                     1                   0   \n",
       "214                     0                     0                   0   \n",
       "466                     0                     0                   0   \n",
       "121                     0                     0                   0   \n",
       "614                     0                     0                   0   \n",
       "20                      0                     0                   0   \n",
       "700                     0                     0                   0   \n",
       "71                      0                     1                   0   \n",
       "106                     0                     1                   0   \n",
       "270                     0                     0                   1   \n",
       "860                     0                     0                   0   \n",
       "435                     0                     0                   0   \n",
       "102                     0                     0                   1   \n",
       "\n",
       "     genderClass_male_2  genderClass_male_3  \n",
       "331                   0                   0  \n",
       "733                   1                   0  \n",
       "382                   0                   1  \n",
       "704                   0                   1  \n",
       "813                   0                   0  \n",
       "118                   0                   0  \n",
       "536                   0                   0  \n",
       "361                   1                   0  \n",
       "29                    0                   1  \n",
       "55                    0                   0  \n",
       "865                   0                   0  \n",
       "595                   0                   1  \n",
       "239                   1                   0  \n",
       "721                   0                   1  \n",
       "81                    0                   1  \n",
       "259                   0                   0  \n",
       "486                   0                   0  \n",
       "716                   0                   0  \n",
       "800                   1                   0  \n",
       "781                   0                   0  \n",
       "542                   0                   0  \n",
       "326                   0                   1  \n",
       "534                   0                   0  \n",
       "535                   0                   0  \n",
       "483                   0                   0  \n",
       "762                   0                   1  \n",
       "533                   0                   0  \n",
       "713                   0                   1  \n",
       "390                   0                   0  \n",
       "495                   0                   1  \n",
       "..                  ...                 ...  \n",
       "276                   0                   0  \n",
       "191                   1                   0  \n",
       "385                   1                   0  \n",
       "805                   0                   1  \n",
       "413                   1                   0  \n",
       "491                   0                   1  \n",
       "343                   1                   0  \n",
       "769                   0                   1  \n",
       "308                   1                   0  \n",
       "661                   0                   1  \n",
       "130                   0                   1  \n",
       "663                   0                   1  \n",
       "871                   0                   0  \n",
       "99                    1                   0  \n",
       "372                   0                   1  \n",
       "87                    0                   1  \n",
       "458                   0                   0  \n",
       "330                   0                   0  \n",
       "214                   0                   1  \n",
       "466                   1                   0  \n",
       "121                   0                   1  \n",
       "614                   0                   1  \n",
       "20                    1                   0  \n",
       "700                   0                   0  \n",
       "71                    0                   0  \n",
       "106                   0                   0  \n",
       "270                   0                   0  \n",
       "860                   0                   1  \n",
       "435                   0                   0  \n",
       "102                   0                   0  \n",
       "\n",
       "[712 rows x 31 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrainDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
