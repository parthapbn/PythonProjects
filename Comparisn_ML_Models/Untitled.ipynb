{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris.data.csv\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-92f99938f624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;31m# 2. Load Dataset to which Machine Learning Algorithm to be applied\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadFrCSVFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mimport2MySQL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDataSetFrMySQLTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-92f99938f624>\u001b[0m in \u001b[0;36mimport2MySQL\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     73\u001b[0m             database  =  'DataScienceRecipes'))\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'strategy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mdbapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dbapi'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\mysql\\pymysql.py\u001b[0m in \u001b[0;36mdbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pymysql'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpy3k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymysql'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "############################################################################\n",
    "# This is an end-2-end Applied Machine Learning Script with RDBMS\n",
    "# Title: Comparing Different Machine Learning Algorithms in Python (for Classification)\n",
    "# Knowledge required: Basic Python, Scikit-Learn and MySQL\n",
    "# System requirements:\n",
    "#   a) Python (3.X) distribution from Anaconda (Anaconda 3)\n",
    "#   b) MySQL 5.7 with an user: root and password:\n",
    "############################################################################\n",
    "\n",
    "\"\"\"\n",
    "@author: \n",
    "    Nilimesh Halder, PhD\n",
    "    BSc in Computer Science and Engineering, \n",
    "        @ Khulna University, Bangladesh.\n",
    "    PhD in Artificial Intelligence and Applied Machine Learning, \n",
    "        @ The University of Western Australia, Australia.\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Steps in Applied Machine Learning:\n",
    "# 1. Load Library\n",
    "# 2. Load Dataset to which Machine Learning Algorithm to be applied\n",
    "#    Either a) load from a CSV file or b) load from a Database   \n",
    "# 3. Summarisation of Data to understand dataset (Descriptive Statistics)\n",
    "# 4. Visualisation of Data to understand dataset (Plots, Graphs etc.)\n",
    "# 5. Data pre-processing & Data transformation (split into train-test datasets)\n",
    "# 6. Application of a Machine Learning Algorithm to training dataset \n",
    "#   a) setup a ML algorithm and parameter settings\n",
    "#   b) cross validation setup with training dataset\n",
    "#   c) training & fitting Algorithm with training Dataset\n",
    "#   d) evaluation of trained Algorithm (or Model) and result\n",
    "#   e) saving the trained model for future prediction\n",
    "# 7. Finalise the trained model and make prediction            \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Load necessary libraries\n",
    "import sqlalchemy as sa\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## --- Load DataSet from CSV file\n",
    "def loadFrCSVFile(filename):\n",
    "    print(filename)\n",
    "    col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "    dataset = pd.read_csv(filename, names=col_names)\n",
    "    return dataset\n",
    "    \n",
    "## --- Import DataSet to a MySQL Database\n",
    "def import2MySQL(dataset):\n",
    "    engine_str = (\n",
    "            'mysql+pymysql://{user}:{password}@{server}/{database}'.format(\n",
    "            user      =  'root',\n",
    "            password  =  'root888',\n",
    "            server    =  'localhost',\n",
    "            database  =  'DataScienceRecipes'))\n",
    "    \n",
    "    engine = sa.create_engine(engine_str)\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    #check whether connection is Successful or not\n",
    "    #if (conn): print(\"MySQL Connection is Successful ... ... ...\")    \n",
    "    #else:      print(\"MySQL Connection is not Successful ... ... ...\")\n",
    "    \n",
    "    dataset.to_sql(name='irisdata', con=engine, schema='datasciencerecipes', \n",
    "                   if_exists = 'replace', chunksize = 1000, index=False)\n",
    "    conn.close()\n",
    "    \n",
    "## --- Load DataSet from MySQL Database to Pandas a DataFrame\n",
    "def loadDataSetFrMySQLTable():\n",
    "    engine_str = (\n",
    "            'mysql+pymysql://{user}:{password}@{server}/{database}'.format(\n",
    "            user      =  'root',\n",
    "            password  =  'root888',\n",
    "            server    =  'localhost',\n",
    "            database  =  'datasciencerecipes'))\n",
    "    \n",
    "    engine = sa.create_engine(engine_str)\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    #check whether connection is Successful or not\n",
    "    #if (conn): print(\"MySQL Connection is Successful ... ... ...\")    \n",
    "    #else:      print(\"MySQL Connection is not Successful ... ... ...\")\n",
    "    \n",
    "    # MySQL Query with few generated Attributes/Features\n",
    "    query = '''\n",
    "    SELECT  sepal_length, \n",
    "            sepal_width, \n",
    "            petal_length, \n",
    "            petal_width, \n",
    "            round(sepal_length/sepal_width,2) as ratio1, \n",
    "            round(sepal_width/petal_length,2) as ratio2,\n",
    "            round(petal_length/petal_width,2) as ratio3,\n",
    "            round(petal_width/sepal_length,2) as ratio4,\n",
    "            round(sepal_width/sepal_length,2) as ratio5, \n",
    "            round(petal_length/sepal_width,2) as ratio6,\n",
    "            round(petal_width/petal_length,2) as ratio7,\n",
    "            round(sepal_length/petal_width,2) as ratio8,\n",
    "            class \n",
    "    FROM irisdata;\n",
    "    '''\n",
    "    \n",
    "    query_result = conn.execute(query)\n",
    "    dataset =  pd.DataFrame(query_result.fetchall(), \n",
    "                            columns =  query_result.keys())\n",
    "    print('DataFrame Size',dataset.shape);\n",
    "    print('ROW',dataset.shape[0]);print('COLUMN',dataset.shape[1]);\n",
    "    conn.close()\n",
    "    return dataset\n",
    "\n",
    "## --- Data Summarisation (Descriptive Statistics)\n",
    "def summariseDataset(dataset):\n",
    "    cols1 = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "    cols2 = ['ratio1','ratio2','ratio3','ratio4']\n",
    "    cols3 = ['ratio5','ratio6','ratio7','ratio8']    \n",
    "    # shape\n",
    "    print(dataset[cols1].shape)\n",
    "    print(dataset[cols2].shape)\n",
    "    print(dataset[cols3].shape)    \n",
    "    # head\n",
    "    print(dataset[cols1].head(5))\n",
    "    print(dataset[cols2].head(5))\n",
    "    print(dataset[cols3].head(5))    \n",
    "    # descriptions\n",
    "    print(dataset[cols1].describe())\n",
    "    print(dataset[cols2].describe())    \n",
    "    print(dataset[cols3].describe())\n",
    "    # class distribution\n",
    "    print(dataset.groupby('class').size())\n",
    "    \n",
    "## --- Data Visualisation to understand Data\n",
    "def visualiseDataset(dataset):\n",
    "    cols1 = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "    cols2 = ['ratio1','ratio2','ratio3','ratio4']\n",
    "    cols3 = ['ratio5','ratio6','ratio7','ratio8'] \n",
    "    \n",
    "    # box and whisker plots\n",
    "    dataset[cols1].plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(12,12))\n",
    "    pyplot.show()\n",
    "    dataset[cols2].plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(12,12))\n",
    "    pyplot.show()\n",
    "    dataset[cols3].plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(12,12))\n",
    "    pyplot.show()    \n",
    "    # histograms\n",
    "    dataset[cols1].hist(figsize=(12,12))\n",
    "    pyplot.show()\n",
    "    dataset[cols2].hist(figsize=(12,12))\n",
    "    pyplot.show()\n",
    "    dataset[cols3].hist(figsize=(12,12))\n",
    "    pyplot.show()    \n",
    "    # scatter plot matrix\n",
    "    scatter_matrix(dataset[cols1], figsize=(12,12))\n",
    "    pyplot.show()\n",
    "    scatter_matrix(dataset[cols2], figsize=(12,12))\n",
    "    pyplot.show()\n",
    "    scatter_matrix(dataset[cols3], figsize=(12,12))\n",
    "    pyplot.show()    \n",
    "\n",
    "## --- Data Pre-Processing\n",
    "def preProcessingData(dataset):\n",
    "    # 1. Data Cleaning\n",
    "      # There is no missing value. \n",
    "      # We could \"Outlier treatment\" but nothing was done here.  \n",
    "    \n",
    "    # 2. Feature Selection\n",
    "    cols_X = ['sepal_length','sepal_width','petal_length','petal_width',\n",
    "              'ratio1','ratio2','ratio3','ratio4',\n",
    "              'ratio5','ratio6','ratio7','ratio8']\n",
    "    cols_Y = 'class'\n",
    "    \n",
    "    # 3. Data Transform - Split out train : test datasets\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(dataset.loc[:, cols_X], \n",
    "                                                        dataset.loc[:, cols_Y], \n",
    "                                                        test_size=0.33,\n",
    "                                                        )\n",
    "    return train_X, test_X, train_Y, test_Y\n",
    "\n",
    "## --- Applied Machine Learning Algorithm ... ... ...\n",
    "def evaluateAlgorithm(train_X, test_X, train_Y, test_Y):\n",
    "    ##Machine Lreaning Algorithm, Parameter setting \n",
    "    \n",
    "    ## Compare different ML Algorithms with default parameter setting    \n",
    "    model_List = []\n",
    "    model_List.append(('LR',    'Logistic Regression',          LogisticRegression()))\n",
    "    model_List.append(('LDA',   'Linear Discriminant Analysis', LinearDiscriminantAnalysis()))\n",
    "    model_List.append(('KNN',   'K Neighbors Classifier',       KNeighborsClassifier()))\n",
    "    model_List.append(('CART',  'DecisionTreeClassifier',       DecisionTreeClassifier()))\n",
    "    model_List.append(('NB',    'Naive Bayes',                  GaussianNB()))\n",
    "    model_List.append(('SVM',   'Support Vector Machine ',      SVC()))    \n",
    "    \n",
    "    ##Cross Validation\n",
    "    print(\"Cross Validation Results \")\n",
    "    outcomes = []\n",
    "    description = []\n",
    "    shortDescription = []\n",
    "    for shtDes, des, model in model_List:\n",
    "        cv_results = cross_val_score(model, train_X, train_Y, cv = 3, \n",
    "                                     scoring='accuracy', n_jobs = -1, verbose = 0)\n",
    "        outcomes.append(cv_results)\n",
    "        description.append(des)\n",
    "        shortDescription.append(shtDes)\n",
    "        prt_string = \"\\n %s:\\n \\tMean Accuracy: %f (Std: %f)\" % (des, cv_results.mean()\n",
    "                                                                    , cv_results.std())\n",
    "        print(prt_string)\n",
    "        \n",
    "    ##Visualise the outcomes / results from Cross Validation\n",
    "    fig = pyplot.figure(figsize = (12,12))\n",
    "    fig.suptitle('Cross Validation Results (Algorithm Comparison)')\n",
    "    ax = fig.add_subplot(111)\n",
    "    pyplot.boxplot(outcomes)\n",
    "    ax.set_xticklabels(shortDescription)\n",
    "    pyplot.show()\n",
    "    \n",
    "    ##Training & Fitting of each Algorithm with training Dataset\n",
    "    print('\\nEvaluate Algorithms (Accuracy, Classification Report, Confusion Matrix) ... ... ... ')\n",
    "    \n",
    "    for shtDes, des, model in model_List:   \n",
    "        \n",
    "        #model fitting or training\n",
    "        trained_Model = model.fit(train_X, train_Y)\n",
    "        \n",
    "        ##Evaluation of trained Algorithm (or Model) and result\n",
    "        pred_Class          = trained_Model.predict(test_X)\n",
    "        acc         = accuracy_score(test_Y, pred_Class)\n",
    "        classReport = classification_report(test_Y, pred_Class)\n",
    "        confMatrix  = confusion_matrix(test_Y, pred_Class) \n",
    "\n",
    "        print(\"\\n%s: \" % (des))\n",
    "        print('The accuracy: {}'.format(acc))\n",
    "        print('The Classification Report:\\n {}'.format(classReport))\n",
    "        print('The Confusion Matrix:\\n {}'.format(confMatrix))\n",
    "\n",
    "        #Save the trained Model\n",
    "        with open('model_'+shtDes+'.pickle', 'wb') as f:\n",
    "                pk.dump(trained_Model, f)\n",
    "\n",
    "## --- Load a (new or existing ) dataset to make prediction \n",
    "def loadPredictionDataset():\n",
    "    engine_str = (\n",
    "            'mysql+pymysql://{user}:{password}@{server}/{database}'.format(\n",
    "            user      =  'root',\n",
    "            password  =  'root888',\n",
    "            server    =  'localhost',\n",
    "            database  =  'datasciencerecipes'))\n",
    "    \n",
    "    engine = sa.create_engine(engine_str)\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    #check whether connection is Successful or not\n",
    "    #if (conn): print(\"MySQL Connection is Successful ... ... ...\")    \n",
    "    #else:      print(\"MySQL Connection is not Successful ... ... ...\")\n",
    "    \n",
    "    # MySQL Query - New Query is required for Prediction DataSet\n",
    "    query = '''\n",
    "    SELECT  sepal_length, \n",
    "            sepal_width, \n",
    "            petal_length, \n",
    "            petal_width, \n",
    "            round(sepal_length/sepal_width,2) as ratio1, \n",
    "            round(sepal_width/petal_length,2) as ratio2,\n",
    "            round(petal_length/petal_width,2) as ratio3,\n",
    "            round(petal_width/sepal_length,2) as ratio4,\n",
    "            round(sepal_width/sepal_length,2) as ratio5, \n",
    "            round(petal_length/sepal_width,2) as ratio6,\n",
    "            round(petal_width/petal_length,2) as ratio7,\n",
    "            round(sepal_length/petal_width,2) as ratio8\n",
    "    FROM irisdata;\n",
    "    '''\n",
    "    \n",
    "    query_result = conn.execute(query)\n",
    "    dataset =  pd.DataFrame(query_result.fetchall(), \n",
    "                            columns =  query_result.keys())\n",
    "    conn.close()\n",
    "    return dataset\n",
    "\n",
    "## --- Load the trained model and make prediction\n",
    "def loadTrainedModelForPrediction(pred_dataset):\n",
    "    # trained models are: \n",
    "    # model_LR, model_LDA, model_KNN, model_CART, model_NB, model_SVM\n",
    "    f = open('model_LDA.pickle', 'rb')\n",
    "    model = pk.load(f); f.close();\n",
    "    pred_Class = model.predict(pred_dataset)\n",
    "    pred_dataset.loc[:, 'classResult'] = pred_Class\n",
    "    return pred_dataset\n",
    "\n",
    "## --- Finalise the results and update the audiance\n",
    "def finaliseResult(result):\n",
    "    \n",
    "    #Save Result in a CSV file\n",
    "    result.to_csv('finalResult.csv', index = False)\n",
    "    print(\"\\n\\nSave Result in a CSV file ... ... Done ...\")    \n",
    "    \n",
    "    #Save Result in a MySQl Table\n",
    "    engine_str = (\n",
    "            'mysql+pymysql://{user}:{password}@{server}/{database}'.format(\n",
    "            user      =  'root',\n",
    "            password  =  'root888',\n",
    "            server    =  'localhost',\n",
    "            database  =  'datasciencerecipes'))\n",
    "    \n",
    "    engine = sa.create_engine(engine_str)\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    #check whether connection is Successful or not\n",
    "    #if (conn): print(\"MySQL Connection is Successful ... ... ...\")    \n",
    "    #else:      print(\"MySQL Connection is not Successful ... ... ...\")\n",
    "    \n",
    "    result.to_sql(name='irisresult', con=engine, schema='datasciencerecipes', \n",
    "                   if_exists = 'replace', chunksize = 1000, index=False)\n",
    "    print(\"Save Result in a MySQl Table ... ... Done ...\")        \n",
    "    conn.close()\n",
    "\n",
    "# End-to-End Applied Machine Learning Recipes for Developers    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = 'iris.data.csv'\n",
    "    \n",
    "    # 2. Load Dataset to which Machine Learning Algorithm to be applied\n",
    "    dataset = loadFrCSVFile(filename)\n",
    "    import2MySQL(dataset)\n",
    "    dataset = loadDataSetFrMySQLTable()\n",
    "    \n",
    "    # 3. Summarisation of Data to understand dataset (Descriptive Statistics)\n",
    "    summariseDataset(dataset)\n",
    "    \n",
    "    # 4. Visualisation of Data to understand dataset (Plots, Graphs etc.)\n",
    "    visualiseDataset(dataset)\n",
    "    \n",
    "    # 5. Data pre-processing and Data transformation (split into train-test datasets)\n",
    "    train_X, test_X, train_Y, test_Y = preProcessingData(dataset)\n",
    "    \n",
    "    # 6. Application of a Machine Learning Algorithm to training dataset \n",
    "    evaluateAlgorithm(train_X, test_X, train_Y, test_Y)\n",
    "    \n",
    "    # 7. Load the saved model and apply it to new dataset for prediction \n",
    "    pred_Dataset = loadPredictionDataset()\n",
    "    result = loadTrainedModelForPrediction(pred_Dataset)\n",
    "    finaliseResult(result)\n",
    "    \n",
    "    print('\\nEnd-to-End Applied Machine Learning Recipes for Developers\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
